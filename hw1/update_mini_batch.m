function [new_weights, new_biases] = update_mini_batch(x_batch, y_batch, weights, biases, eta, nodeLayers, cost_function)    new_weights = {};    new_biases = {};    # Get the change in the weights and biases for the given batch    [nabla_w, nabla_b] = backprop(x_batch, y_batch, weights, biases, nodeLayers, cost_function);        # Update the weights and biases on each layer    for layer_idx = 1:columns(weights)        # new weight is wL - (learning rate / N) * dw/dc(L+!)        new_weights{layer_idx} = weights{layer_idx} - eta/rows(x_batch) * nabla_w{layer_idx + 1}';        # new bias is bL - (learning rate / N) * db/dc(L+!)        new_biases{layer_idx} = biases{layer_idx} - eta/rows(x_batch) * nabla_b{layer_idx + 1};    endforendfunction