function [weights, biases] = sgd (inputs, targets, nodeLayers, numEpochs, batchSize, eta=.1, tvt_split=[.6, .2, .2], cost_function='mse', momentum_coefficient=1, lambda=1, transform='sigmoid', weights=false, biases=false)    # New inputs:        # tvt_split: vector of three floats between 0 and 1 that designates the             # proportion of the data that will be used for training, validation, and testing            # respectively        # cost_function: the designated cost function to evaluate the predictor by             # mse - Mean Square Error            # log-likelihood - Log Likelihood            # cross-entropy - Cross Entropy        # momentum_coefficient        # lambda - Regularization coefficient        # transform - Transformation function            # sigmoid            # relu            # tanh            # softmax        # weights - input weights from previous training session        # biases - input biases from previous training session            # Initialize the weights and biases    if (weights==false)        weights = initialize_weights(nodeLayers, batchSize);    endif    if (biases==false)        biases = initialize_biases(nodeLayers);    endif        [train_data, validation_data, test_data] = get_train_validation_test_split(inputs, targets, tvt_split);    datasets = {train_data, test_data, validation_data};    velocity = get_nabla_w(nodeLayers);    num_examples = length(train_data{1});    print_header();    errors = [];        # loop through a total number of the epochs entered as input    for epoch = 1:numEpochs        # Get the correct x and y batches based on the input batch size        [x_batches, y_batches] = get_minibatches(train_data{1}, train_data{2}, batchSize);        for idx = 1:length(x_batches)            # update the weights based on batched SGD            [weights, biases, velocity] = update_mini_batch(x_batches{idx}, y_batches{idx}, weights, biases, eta, nodeLayers, cost_function, momentum_coefficient, velocity, lambda, num_examples);        endfor        # Now that the batches for the epoch are complete, lets see how we're doing        error = report_performance(epoch, datasets, weights, biases, cost_function);                errors(end + 1) = error;        if (epoch > 10)            if (errors(epoch - 10) <= errors(epoch))                break;            endif        endif     endforendfunction